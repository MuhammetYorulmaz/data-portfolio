{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import make_scorer, root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine_category_alcohol-plus-food</th>\n",
       "      <th>cuisine_category_chocolate</th>\n",
       "      <th>cuisine_category_belgian</th>\n",
       "      <th>cuisine_category_lebanese</th>\n",
       "      <th>cuisine_category_russian</th>\n",
       "      <th>cuisine_category_african</th>\n",
       "      <th>cuisine_category_european</th>\n",
       "      <th>cuisine_category_gluten-free</th>\n",
       "      <th>cuisine_category_comfort-food</th>\n",
       "      <th>cuisine_category_moroccan</th>\n",
       "      <th>...</th>\n",
       "      <th>cuisine_category_japanese</th>\n",
       "      <th>total_items</th>\n",
       "      <th>cuisine_category_mexican</th>\n",
       "      <th>cuisine_category_pizza</th>\n",
       "      <th>cuisine_category_american</th>\n",
       "      <th>avg_price_per_item</th>\n",
       "      <th>busy_dashers_ratio</th>\n",
       "      <th>estimated_store_to_consumer_driving_duration</th>\n",
       "      <th>estimated_order_place_duration</th>\n",
       "      <th>total_delivery_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860.25</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>861.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>690.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>4024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1192.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>289.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1525.00</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>795.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>2273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1810.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>2988.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cuisine_category_alcohol-plus-food  cuisine_category_chocolate  \\\n",
       "0                                 0.0                         0.0   \n",
       "1                                 0.0                         0.0   \n",
       "2                                 0.0                         0.0   \n",
       "3                                 0.0                         0.0   \n",
       "4                                 0.0                         0.0   \n",
       "\n",
       "   cuisine_category_belgian  cuisine_category_lebanese  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   cuisine_category_russian  cuisine_category_african  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   cuisine_category_european  cuisine_category_gluten-free  \\\n",
       "0                        0.0                           0.0   \n",
       "1                        0.0                           0.0   \n",
       "2                        0.0                           0.0   \n",
       "3                        0.0                           0.0   \n",
       "4                        0.0                           0.0   \n",
       "\n",
       "   cuisine_category_comfort-food  cuisine_category_moroccan  ...  \\\n",
       "0                            0.0                        0.0  ...   \n",
       "1                            0.0                        0.0  ...   \n",
       "2                            0.0                        0.0  ...   \n",
       "3                            0.0                        0.0  ...   \n",
       "4                            0.0                        0.0  ...   \n",
       "\n",
       "   cuisine_category_japanese  total_items  cuisine_category_mexican  \\\n",
       "0                        0.0          4.0                       0.0   \n",
       "1                        0.0          1.0                       1.0   \n",
       "2                        0.0          4.0                       0.0   \n",
       "3                        0.0          1.0                       0.0   \n",
       "4                        0.0          2.0                       0.0   \n",
       "\n",
       "   cuisine_category_pizza  cuisine_category_american  avg_price_per_item  \\\n",
       "0                     0.0                        1.0              860.25   \n",
       "1                     0.0                        0.0             1900.00   \n",
       "2                     0.0                        0.0             1192.75   \n",
       "3                     0.0                        0.0             1525.00   \n",
       "4                     0.0                        0.0             1810.00   \n",
       "\n",
       "   busy_dashers_ratio  estimated_store_to_consumer_driving_duration  \\\n",
       "0            0.424242                                         861.0   \n",
       "1            2.000000                                         690.0   \n",
       "2            0.750000                                         289.0   \n",
       "3            1.200000                                         795.0   \n",
       "4            1.000000                                         205.0   \n",
       "\n",
       "   estimated_order_place_duration  total_delivery_duration  \n",
       "0                           446.0                   3779.0  \n",
       "1                           446.0                   4024.0  \n",
       "2                           446.0                   1586.0  \n",
       "3                           446.0                   2273.0  \n",
       "4                           446.0                   2988.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/df_after_feature_engineering.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total_delivery_duration')\n",
    "y = df['total_delivery_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE function for inverse scaling\n",
    "def rmse_inverse(y_true, y_pred, y_scaler):\n",
    "    y_true_orig = y_scaler.inverse_transform(y_true.reshape(-1, 1))\n",
    "    y_pred_orig = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    return root_mean_squared_error(y_true_orig, y_pred_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression function\n",
    "def create_regression(X, y, model, model_name, scaler_name, y_scaler=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains a regression model using cross-validation and computes RMSE.\n",
    "    Handles scaled and unscaled data correctly.\n",
    "\n",
    "    Args:\n",
    "    - X: Features (scaled or unscaled)\n",
    "    - y: Target variable (scaled or unscaled)\n",
    "    - model: Regression model to use\n",
    "    - model_name: Name of the model\n",
    "    - scaler_name: Name of the scaler used\n",
    "    - y_scaler: Target scaler for inverse scaling RMSE (if applicable)\n",
    "    - verbose: Whether to print detailed output\n",
    "\n",
    "    Returns:\n",
    "    - rmse_scores: List of RMSE scores across folds\n",
    "    - elapsed_time: Total time taken for cross-validation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    if scaler_name != 'Without Scale' and y_scaler is not None:\n",
    "        # Use inverse RMSE scoring for scaled data\n",
    "        rmse_scorer = make_scorer(lambda y_true, y_pred: rmse_inverse(y_true, y_pred, y_scaler), greater_is_better=False)\n",
    "    else:\n",
    "        # Use regular RMSE scoring for unscaled data\n",
    "        rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "        \n",
    "    # Perform cross-validation\n",
    "    rmse_scores = cross_val_score(model, X, y, cv=kf, scoring=rmse_scorer)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Average RMSE : {-np.mean(rmse_scores):.4f} - Time taken: {elapsed_time:.4f} seconds')\n",
    "\n",
    "    return -np.mean(rmse_scores), round(elapsed_time, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling function\n",
    "def scale(scaler, X, y):\n",
    "    \"\"\"\n",
    "    Scales features and target variable using the given scaler.\n",
    "\n",
    "    Args:\n",
    "    - scaler: Instance of sklearn scaler (e.g., MinMaxScaler, StandardScaler)\n",
    "    - X: Features\n",
    "    - y: Target variable\n",
    "\n",
    "    Returns:\n",
    "    - X_scaled: Scaled features\n",
    "    - y_scaled: Scaled target variable\n",
    "    - y_scaler: Scaler instance for the target variable\n",
    "    \"\"\"\n",
    "    X_scaler = scaler\n",
    "    y_scaler = scaler\n",
    "\n",
    "    X_scaled = X_scaler.fit_transform(X)\n",
    "    y_scaled = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "    \n",
    "    return X_scaled, y_scaled, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structures to store results\n",
    "pred_dict = {\n",
    "    \"regression_model\": [],\n",
    "    \"feature_set\": [],\n",
    "    \"scaler_name\": [],\n",
    "    \"RMSE\": [],\n",
    "    \"time_taken\": []\n",
    "}\n",
    "\n",
    "# Regression models\n",
    "regression_models = {\n",
    "    \"AdaBoost\": AdaBoostRegressor(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=6),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"LGBM\": LGBMRegressor()\n",
    "}\n",
    "\n",
    "# Feature sets\n",
    "feature_sets = {\n",
    "    \"All Features\": X.columns.to_list()\n",
    "}\n",
    "\n",
    "# Scalers\n",
    "scalers = {\n",
    "    \"Standard Scaler\": StandardScaler(),\n",
    "    \"Min-Max Scaler\": MinMaxScaler(),\n",
    "    \"Without Scale\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included Columns: All Features | Scaling Method: Standard Scaler | Algorithm Used: AdaBoost\n",
      "Average RMSE : 3454.5769 - Time taken: 75.7516 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Standard Scaler | Algorithm Used: DecisionTree\n",
      "Average RMSE : 1076.4030 - Time taken: 3.5434 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Standard Scaler | Algorithm Used: GradientBoosting\n",
      "Average RMSE : 1043.9634 - Time taken: 189.9971 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Standard Scaler | Algorithm Used: XGBoost\n",
      "Average RMSE : 1044.2271 - Time taken: 6.9361 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Standard Scaler | Algorithm Used: LGBM\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 0.001473\n",
      "[LightGBM] [Info] Total Bins 1533\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 0.000313\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 0.001125\n",
      "[LightGBM] [Info] Total Bins 1531\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -0.000638\n",
      "[LightGBM] [Info] Total Bins 1523\n",
      "[LightGBM] [Info] Number of data points in the train set: 137588, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "Average RMSE : 1037.2224 - Time taken: 5.8213 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Min-Max Scaler | Algorithm Used: AdaBoost\n",
      "Average RMSE : 2800.6198 - Time taken: 64.1361 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Min-Max Scaler | Algorithm Used: DecisionTree\n",
      "Average RMSE : 1076.4030 - Time taken: 3.8422 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Min-Max Scaler | Algorithm Used: GradientBoosting\n",
      "Average RMSE : 1043.9698 - Time taken: 182.9733 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Min-Max Scaler | Algorithm Used: XGBoost\n",
      "Average RMSE : 1044.4811 - Time taken: 6.3458 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Min-Max Scaler | Algorithm Used: LGBM\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 0.048351\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 0.048328\n",
      "[LightGBM] [Info] Total Bins 1464\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 0.048344\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 0.048309\n",
      "[LightGBM] [Info] Total Bins 1459\n",
      "[LightGBM] [Info] Number of data points in the train set: 137588, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 0.048275\n",
      "Average RMSE : 1037.7558 - Time taken: 3.6045 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Without Scale | Algorithm Used: AdaBoost\n",
      "Average RMSE : 4187.3161 - Time taken: 107.6670 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Without Scale | Algorithm Used: DecisionTree\n",
      "Average RMSE : 1076.4030 - Time taken: 2.9496 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Without Scale | Algorithm Used: GradientBoosting\n",
      "Average RMSE : 1043.9711 - Time taken: 101.4466 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Without Scale | Algorithm Used: XGBoost\n",
      "Average RMSE : 1044.2271 - Time taken: 6.3346 seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Included Columns: All Features | Scaling Method: Without Scale | Algorithm Used: LGBM\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 2853.695589\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 2852.356305\n",
      "[LightGBM] [Info] Total Bins 1465\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 2853.294083\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 137587, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 2851.257212\n",
      "[LightGBM] [Info] Total Bins 1460\n",
      "[LightGBM] [Info] Number of data points in the train set: 137588, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score 2849.370054\n",
      "Average RMSE : 1037.6285 - Time taken: 5.0804 seconds\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Main loop for feature sets, scalers, and regression models\n",
    "for feature_set_name, features in feature_sets.items():\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        for model_name, model in regression_models.items():\n",
    "            print(f\"Included Columns: {feature_set_name} | Scaling Method: {scaler_name} | Algorithm Used: {model_name}\")\n",
    "\n",
    "            # Select features and target variable\n",
    "            X = df[features]\n",
    "            y = df['total_delivery_duration']\n",
    "            \n",
    "            # Model-specific adjustments\n",
    "            if model_name == \"LGBM\":\n",
    "                model.set_params(force_col_wise=True)\n",
    "\n",
    "            if scaler_name == 'Without Scale':\n",
    "                # Unscaled data\n",
    "                avg_rmse_error, time_taken = create_regression(X, y, model, model_name, scaler_name, verbose=True)\n",
    "            else:\n",
    "                # Scaled data\n",
    "                X_scaled, y_scaled, y_scaler = scale(scaler, X, y)\n",
    "                avg_rmse_error, time_taken = create_regression(X_scaled, y_scaled[:, 0], model, model_name, scaler_name, y_scaler=y_scaler, verbose=True)\n",
    "\n",
    "            print('-' * 100)\n",
    "\n",
    "            # Store results in pred_dict\n",
    "            pred_dict['regression_model'].append(model_name)\n",
    "            pred_dict['feature_set'].append(feature_set_name)\n",
    "            pred_dict['scaler_name'].append(scaler_name)\n",
    "            pred_dict['RMSE'].append(avg_rmse_error)\n",
    "            pred_dict['time_taken'].append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regression_model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>scaler_name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>1037.222363</td>\n",
       "      <td>5.8213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Without Scale</td>\n",
       "      <td>1037.628511</td>\n",
       "      <td>5.0804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Min-Max Scaler</td>\n",
       "      <td>1037.755774</td>\n",
       "      <td>3.6045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>1043.963364</td>\n",
       "      <td>189.9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Min-Max Scaler</td>\n",
       "      <td>1043.969762</td>\n",
       "      <td>182.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Without Scale</td>\n",
       "      <td>1043.971064</td>\n",
       "      <td>101.4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Without Scale</td>\n",
       "      <td>1044.227140</td>\n",
       "      <td>6.3346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>1044.227141</td>\n",
       "      <td>6.9361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Min-Max Scaler</td>\n",
       "      <td>1044.481077</td>\n",
       "      <td>6.3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Without Scale</td>\n",
       "      <td>1076.402980</td>\n",
       "      <td>2.9496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>1076.402980</td>\n",
       "      <td>3.5434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Min-Max Scaler</td>\n",
       "      <td>1076.402980</td>\n",
       "      <td>3.8422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Min-Max Scaler</td>\n",
       "      <td>2800.619832</td>\n",
       "      <td>64.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>3454.576882</td>\n",
       "      <td>75.7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Without Scale</td>\n",
       "      <td>4187.316090</td>\n",
       "      <td>107.6670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regression_model   feature_set      scaler_name         RMSE  time_taken\n",
       "4               LGBM  All Features  Standard Scaler  1037.222363      5.8213\n",
       "14              LGBM  All Features    Without Scale  1037.628511      5.0804\n",
       "9               LGBM  All Features   Min-Max Scaler  1037.755774      3.6045\n",
       "2   GradientBoosting  All Features  Standard Scaler  1043.963364    189.9971\n",
       "7   GradientBoosting  All Features   Min-Max Scaler  1043.969762    182.9733\n",
       "12  GradientBoosting  All Features    Without Scale  1043.971064    101.4466\n",
       "13           XGBoost  All Features    Without Scale  1044.227140      6.3346\n",
       "3            XGBoost  All Features  Standard Scaler  1044.227141      6.9361\n",
       "8            XGBoost  All Features   Min-Max Scaler  1044.481077      6.3458\n",
       "11      DecisionTree  All Features    Without Scale  1076.402980      2.9496\n",
       "1       DecisionTree  All Features  Standard Scaler  1076.402980      3.5434\n",
       "6       DecisionTree  All Features   Min-Max Scaler  1076.402980      3.8422\n",
       "5           AdaBoost  All Features   Min-Max Scaler  2800.619832     64.1361\n",
       "0           AdaBoost  All Features  Standard Scaler  3454.576882     75.7516\n",
       "10          AdaBoost  All Features    Without Scale  4187.316090    107.6670"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=pred_dict).sort_values(by='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_before_feature_eng = pd.read_csv('../data/processed/df_before_feature_eng.csv')\n",
    "# df_before_feature_eng.head()\n",
    "# X = df_before_feature_eng.drop(columns=['total_delivery_duration'])\n",
    "# y = df_before_feature_eng['total_delivery_duration']\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "# rmse_scores = cross_val_score(LGBMRegressor(), X, y, cv=kf, scoring=rmse_scorer)\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# print(f'Average RMSE : {-np.mean(rmse_scores):.4f} - Time taken: {elapsed_time:.4f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delivery_duration_prediction_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
